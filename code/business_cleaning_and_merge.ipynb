{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning For Business Data and Merging with Review\n",
    "\n",
    "## Input\n",
    "1. business_train.json\n",
    "2. review_brunch.csv\n",
    "\n",
    "## Output\n",
    "1. 628_brunch_lv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *  # for what???\n",
    "from operator import or_\n",
    "import datetime  # For hours' format\n",
    "import re   # For categories' matching\n",
    "import os  # For working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_brunch = pd.read_csv('review_brunch.csv', lineterminator='\\n', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40775.0</td>\n",
       "      <td>2017-12-15 23:27:08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>walk around friday afternoon sit table bar wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64416.0</td>\n",
       "      <td>2016-07-25 03:57:19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pick meat planet chef make mexican style dish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>145384.0</td>\n",
       "      <td>2018-05-28 20:56:05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>party order fish taco pork belly banh mi corn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    business_id                 date  stars  \\\n",
       "10      40775.0  2017-12-15 23:27:08    1.0   \n",
       "19      64416.0  2016-07-25 03:57:19    5.0   \n",
       "35     145384.0  2018-05-28 20:56:05    5.0   \n",
       "\n",
       "                                       processed_text  \n",
       "10  walk around friday afternoon sit table bar wal...  \n",
       "19  pick meat planet chef make mexican style dish ...  \n",
       "35  party order fish taco pork belly banh mi corn ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_brunch.iloc[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521672, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_brunch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_train = []\n",
    "for line in open ('business_train.json','r'):\n",
    "    bus_train.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus_train = pd.DataFrame.from_dict(bus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_bus_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcols = [cols[1],cols[8],cols[3],cols[10],cols[9],cols[6],cols[7],cols[5],cols[0],cols[2],cols[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus_1 = df_bus_train[newcols]\n",
    "attributes = df_bus_train['attributes']\n",
    "hours = df_bus_train['hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attributes = set(attributes[0].keys())\n",
    "for i in range(1,len(attributes)): \n",
    "    if pd.isna(attributes[i])==False:\n",
    "        all_attributes = all_attributes.union(set(attributes[i].keys()))\n",
    "len(all_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributes = list(all_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hrs = []\n",
    "for i in range(len(hours)): \n",
    "    if pd.isna(hours[i])==False:\n",
    "        all_hrs = list(set(all_hrs + list(hours[i].keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25982\\AppData\\Local\\conda\\conda\\envs\\stat 628\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_attributes)):\n",
    "    alist = []\n",
    "    for j in range(len(attributes)):\n",
    "            if pd.isna(attributes[j])==False:\n",
    "                if all_attributes[i] in set(attributes[j].keys()):\n",
    "                    alist.append(attributes[j][all_attributes[i]])\n",
    "                else: alist.append('NA')\n",
    "            else: alist.append('NA')\n",
    "    df_bus_1[all_attributes[i]]=alist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25982\\AppData\\Local\\conda\\conda\\envs\\stat 628\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_hrs)):\n",
    "    blist = []\n",
    "    for j in range(len(hours)):\n",
    "            if pd.isna(hours[j])==False:\n",
    "                if all_hrs[i] in set(hours[j].keys()):\n",
    "                    blist.append(hours[j][all_hrs[i]])\n",
    "                else: blist.append('NA')\n",
    "            else: blist.append('NA')\n",
    "    df_bus_1[all_hrs[i]]=blist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25982\\AppData\\Local\\conda\\conda\\envs\\stat 628\\lib\\site-packages\\pandas\\core\\frame.py:3391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "df_bus_1[['Monday_open','Monday_close']]=df_bus_1.pop('Monday').str.extract('(.*)-(.*)',  expand=True)\n",
    "df_bus_1[['Tuesday_open','Tuesday_close']]=df_bus_1.pop('Tuesday').str.extract('(.*)-(.*)',  expand=True)\n",
    "df_bus_1[['Wednesday_open','Wednesday_close']]=df_bus_1.pop('Wednesday').str.extract('(.*)-(Sunday.*)',  expand=True)\n",
    "df_bus_1[['Thursday_open','Thursday_close']]=df_bus_1.pop('Thursday').str.extract('(.*)-(.*)',  expand=True)\n",
    "df_bus_1[['Friday_open','Friday_close']]=df_bus_1.pop('Friday').str.extract('(.*)-(.*)',  expand=True)\n",
    "df_bus_1[['Saturday_open','Saturday_close']]=df_bus_1.pop('Saturday').str.extract('(.*)-(.*)',  expand=True)\n",
    "df_bus_1[['Sunday_open','Sunday_close']]=df_bus_1.pop('Sunday').str.extract('(.*)-(.*)',  expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25982\\AppData\\Local\\conda\\conda\\envs\\stat 628\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "week_day = [\"Monday\", \"Tuesday\" ,\"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "for temp_day in week_day:\n",
    "    time_open = df_bus_1[temp_day+'_open'].replace(np.nan, '', regex=True)\n",
    "    time_open_datetime = (pd.Series ([datetime.datetime.strptime(item, \"%H:%M\") if item != '' else None\n",
    "                                     for item in time_open ]))\n",
    "    time_close = df_bus_1[temp_day+'_close'].replace(np.nan, '', regex=True)\n",
    "    time_close_datetime = (pd.Series ([datetime.datetime.strptime(item, \"%H:%M\") if item != '' else None\n",
    "                                     for item in time_close ]))\n",
    "    time_diff_1=(time_close_datetime-time_open_datetime)/np.timedelta64(1, 'h')\n",
    "    time_diff_1[time_diff_1 <= 0]=time_diff_1[time_diff_1 <= 0]+24\n",
    "    time_diff_1[time_diff_1.isnull() & df_bus_1[['hours']].notnull().iloc[:,0]] = 0\n",
    "    df_bus_1[temp_day+\"_hours\"] = time_diff_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_day in week_day:\n",
    "        df_bus_1=df_bus_1.drop(columns=[temp_day+'_open',temp_day+'_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus_brunch=df_bus_1[df_bus_1['categories'].str.contains('Breakfast & Brunch', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4322, 57)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bus_brunch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( df_bus_brunch['city'].str.match('Las Vegas', na=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_review_brunch.merge(df_bus_brunch, how = 'left', on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521672, 60)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_brunch = df_merge[df_merge['categories'].str.contains('Breakfast & Brunch', na=False)]\n",
    "df_merge_brunch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169529, 60)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_brunch_lv = df_merge_brunch[df_merge_brunch['city'].str.match('Las Vegas', na=False)]\n",
    "df_merge_brunch_lv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_brunch_lv.to_csv('628_brunch_lv.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
